{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.005106Z",
     "iopub.status.busy": "2022-05-07T14:12:30.004829Z",
     "iopub.status.idle": "2022-05-07T14:12:30.013019Z",
     "shell.execute_reply": "2022-05-07T14:12:30.012341Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.005074Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Exploratory Data Analysis****\n",
    "\n",
    "The Goal of this analysis is to uncover any insights or trends in the catalogue of films and TV shows available on the Netflix website.\n",
    "\n",
    "First I will import the dataset that to see the parameters I have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.014965Z",
     "iopub.status.busy": "2022-05-07T14:12:30.014168Z",
     "iopub.status.idle": "2022-05-07T14:12:30.110826Z",
     "shell.execute_reply": "2022-05-07T14:12:30.110014Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.014925Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/netflix-shows/netflix_titles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-618d5ed09125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/netflix-shows/netflix_titles.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/netflix-shows/netflix_titles.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/netflix-shows/netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.112329Z",
     "iopub.status.busy": "2022-05-07T14:12:30.112064Z",
     "iopub.status.idle": "2022-05-07T14:12:30.131774Z",
     "shell.execute_reply": "2022-05-07T14:12:30.130735Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.112297Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.134027Z",
     "iopub.status.busy": "2022-05-07T14:12:30.133539Z",
     "iopub.status.idle": "2022-05-07T14:12:30.141185Z",
     "shell.execute_reply": "2022-05-07T14:12:30.140327Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.133980Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data imported, the above line of code shows the columns that we have to work with many of which are self explanatory, but I will highlight a the below:\n",
    "* Show ID - This tells us what season the show is, if a TV show \n",
    "* Type - Whether it's a Movie or TV-Show\n",
    "* Listed in - The category that the TV-Show  or film falls under e.g. Documentary or Action\n",
    "* Rating - the audiences that the film or TV-Show is safe for vieiwing for \n",
    "\n",
    "Now that the data is imported, the next step is to Process or clean the data for analysis, I will begin first by checking for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.143419Z",
     "iopub.status.busy": "2022-05-07T14:12:30.142705Z",
     "iopub.status.idle": "2022-05-07T14:12:30.164857Z",
     "shell.execute_reply": "2022-05-07T14:12:30.164013Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.143370Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_data = df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.166565Z",
     "iopub.status.busy": "2022-05-07T14:12:30.165847Z",
     "iopub.status.idle": "2022-05-07T14:12:30.185416Z",
     "shell.execute_reply": "2022-05-07T14:12:30.184484Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.166525Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I have created a dataframe that tells me for which values are missing, values that are missing are True and those which are not are False. This can be difficult to view so to make it easier to see, let's count the amount of missing data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.186742Z",
     "iopub.status.busy": "2022-05-07T14:12:30.186532Z",
     "iopub.status.idle": "2022-05-07T14:12:30.211280Z",
     "shell.execute_reply": "2022-05-07T14:12:30.210389Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.186716Z"
    }
   },
   "outputs": [],
   "source": [
    "for column in missing_data.columns.tolist():\n",
    "    print(column)\n",
    "    print(missing_data[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can see that there a missing values in the columns; \n",
    "* Director\n",
    "* Cast\n",
    "* Country\n",
    "* Date-added\n",
    "* Rating\n",
    "* Duration\n",
    "\n",
    "For some columns I will ignore these missing values, e.g cast and director. But I will fix some of the other columns.\n",
    "First Ratings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.213144Z",
     "iopub.status.busy": "2022-05-07T14:12:30.212906Z",
     "iopub.status.idle": "2022-05-07T14:12:30.223736Z",
     "shell.execute_reply": "2022-05-07T14:12:30.222774Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.213115Z"
    }
   },
   "outputs": [],
   "source": [
    "df['rating'].value_counts().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that some of the ratings have durations instead, this may be an error where the data has been transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.225534Z",
     "iopub.status.busy": "2022-05-07T14:12:30.225253Z",
     "iopub.status.idle": "2022-05-07T14:12:30.240417Z",
     "shell.execute_reply": "2022-05-07T14:12:30.239763Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.225502Z"
    }
   },
   "outputs": [],
   "source": [
    "df['duration'].value_counts().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's isolate these rows and see what has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.242199Z",
     "iopub.status.busy": "2022-05-07T14:12:30.241785Z",
     "iopub.status.idle": "2022-05-07T14:12:30.275023Z",
     "shell.execute_reply": "2022-05-07T14:12:30.273524Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.242163Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.loc[df['rating'] == '66 min'])\n",
    "print(df.loc[df['rating'] == '84 min'])\n",
    "print(df.loc[df['rating'] == '74 min'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be an error with the titles by the comedian Louis CK, a quick look up on the Netflix website will tell us what the correct rating is for these shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.276973Z",
     "iopub.status.busy": "2022-05-07T14:12:30.276081Z",
     "iopub.status.idle": "2022-05-07T14:12:30.287704Z",
     "shell.execute_reply": "2022-05-07T14:12:30.286758Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.276917Z"
    }
   },
   "outputs": [],
   "source": [
    "#Louis C.K.: Live at the Comedy Store 1 hr 5 min (15 - tvma)\n",
    "#Louis C.K.: Hilarious 1 hr 23 min (18)\n",
    "#Louis C.K. 2017 1 hr 14 min (15 - tvma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the correct rating we can now move the values for duration into the correct column and input the correct rating also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.289238Z",
     "iopub.status.busy": "2022-05-07T14:12:30.288887Z",
     "iopub.status.idle": "2022-05-07T14:12:30.304808Z",
     "shell.execute_reply": "2022-05-07T14:12:30.303595Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.289209Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[5813, df.columns.get_loc('duration')] = \"66 min\"\n",
    "df.iloc[5813, df.columns.get_loc('rating')] = \"TV-MA\"\n",
    "df.iloc[5794, df.columns.get_loc('duration')] = \"84 min\"\n",
    "df.iloc[5794, df.columns.get_loc('rating')] = \"TV-MA\"\n",
    "df.iloc[5541, df.columns.get_loc('duration')] = \"74 min\"\n",
    "df.iloc[5541, df.columns.get_loc('rating')] = \"TV-MA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.307739Z",
     "iopub.status.busy": "2022-05-07T14:12:30.306642Z",
     "iopub.status.idle": "2022-05-07T14:12:30.320818Z",
     "shell.execute_reply": "2022-05-07T14:12:30.319912Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.307686Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[5813]\n",
    "df.iloc[5794]\n",
    "df.iloc[5541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.322652Z",
     "iopub.status.busy": "2022-05-07T14:12:30.321818Z",
     "iopub.status.idle": "2022-05-07T14:12:30.336762Z",
     "shell.execute_reply": "2022-05-07T14:12:30.335844Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.322614Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df['duration'].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have dealt with mising values in the duration column, now let's turn our attention back to ratings column, rather than searching the titles of the missing values, instead I am going to replace the misisng values with the most common; TV-MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.338277Z",
     "iopub.status.busy": "2022-05-07T14:12:30.338030Z",
     "iopub.status.idle": "2022-05-07T14:12:30.349144Z",
     "shell.execute_reply": "2022-05-07T14:12:30.348474Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.338245Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"rating\"].replace(np.nan, \"TV-MA\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.350840Z",
     "iopub.status.busy": "2022-05-07T14:12:30.350562Z",
     "iopub.status.idle": "2022-05-07T14:12:30.362942Z",
     "shell.execute_reply": "2022-05-07T14:12:30.362093Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.350808Z"
    }
   },
   "outputs": [],
   "source": [
    "df['rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, another column down. Now let's take a look at Date_added.\n",
    "The data in this column shows the date that the title was added to Netflix, this data may be hard to find, instead of wasting time, I'm going to remove these rows from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.365308Z",
     "iopub.status.busy": "2022-05-07T14:12:30.364223Z",
     "iopub.status.idle": "2022-05-07T14:12:30.381253Z",
     "shell.execute_reply": "2022-05-07T14:12:30.380193Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.365252Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"date_added\"], axis=0, inplace=True)\n",
    "# reset index, because we droped some rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.382946Z",
     "iopub.status.busy": "2022-05-07T14:12:30.382441Z",
     "iopub.status.idle": "2022-05-07T14:12:30.395738Z",
     "shell.execute_reply": "2022-05-07T14:12:30.394659Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.382907Z"
    }
   },
   "outputs": [],
   "source": [
    "df['date_added'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that we also have no null rows in the Date Added column, great. For the columns Director, Cast and Country that still contain missing data, I will cgoose to ignore these. Now that I am happy with the state of the data I can begin my analsysis.\n",
    "\n",
    "The aim of this project is to explore the data that is available on Netflix, from the column names we know that Netlix offers TV-Shows and Movies. But in what proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.397490Z",
     "iopub.status.busy": "2022-05-07T14:12:30.397102Z",
     "iopub.status.idle": "2022-05-07T14:12:30.416395Z",
     "shell.execute_reply": "2022-05-07T14:12:30.415739Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.397450Z"
    }
   },
   "outputs": [],
   "source": [
    "pie_data = df.groupby(['type'])['show_id'].count().reset_index()\n",
    "pie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.421175Z",
     "iopub.status.busy": "2022-05-07T14:12:30.420758Z",
     "iopub.status.idle": "2022-05-07T14:12:30.472881Z",
     "shell.execute_reply": "2022-05-07T14:12:30.472096Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.421144Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.pie(pie_data, values='show_id', names='type', title='Proportion of Movies vs TV Shows on Netflix') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pie chart shows us that the majority of the Netflix catalogue consists of movies, about a 70:30 split between movies and TV Shows. Given that the majority of the titles on Netflix, let's take a closer look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.474455Z",
     "iopub.status.busy": "2022-05-07T14:12:30.474046Z",
     "iopub.status.idle": "2022-05-07T14:12:30.493384Z",
     "shell.execute_reply": "2022-05-07T14:12:30.492470Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.474404Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_data = df.groupby(['release_year','type'])['show_id'].count().reset_index()\n",
    "hist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.494958Z",
     "iopub.status.busy": "2022-05-07T14:12:30.494599Z",
     "iopub.status.idle": "2022-05-07T14:12:30.568273Z",
     "shell.execute_reply": "2022-05-07T14:12:30.567348Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.494927Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(hist_data, x=\"release_year\", y='show_id', color=\"type\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bar chart to show the the amount of movies and TV-shows on Netflix by release year. On the x-axis we have release year and on the y-axis the sum of titles released, with Movies indicated by the red bar and TV-shows indicated by thr blue .\n",
    "From the histogram, we can see that the Netflix catalogue has a range of movies from 1942, to 2021 with the majority of the movies being released in the year 2021 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we have an idea of the quantity of movies and there release dates I'd like to see if there is any information that can be \n",
    "gathered from the country data.\n",
    "I begin by creating a new dataframe of just the countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.570325Z",
     "iopub.status.busy": "2022-05-07T14:12:30.569993Z",
     "iopub.status.idle": "2022-05-07T14:12:30.583037Z",
     "shell.execute_reply": "2022-05-07T14:12:30.581923Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.570280Z"
    }
   },
   "outputs": [],
   "source": [
    "countries = df['country'].value_counts()\n",
    "\n",
    "countries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to create a list of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.585518Z",
     "iopub.status.busy": "2022-05-07T14:12:30.584561Z",
     "iopub.status.idle": "2022-05-07T14:12:30.592483Z",
     "shell.execute_reply": "2022-05-07T14:12:30.591620Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.585410Z"
    }
   },
   "outputs": [],
   "source": [
    "country_list = ['United States', 'India', 'United Kingdom', 'Japan', 'South Korea', 'Canada',\n",
    "              'Spain', 'France', 'Mexico', 'Egypt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to drop the countries that aren't in the top 10 country list and rename the show ID column to count or sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.594107Z",
     "iopub.status.busy": "2022-05-07T14:12:30.593800Z",
     "iopub.status.idle": "2022-05-07T14:12:30.622027Z",
     "shell.execute_reply": "2022-05-07T14:12:30.621023Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.594066Z"
    }
   },
   "outputs": [],
   "source": [
    "country_df = df[df['country'].isin(country_list)].reset_index()\n",
    "country_df =country_df.groupby(['country','type'])['show_id'].count().reset_index()\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.623677Z",
     "iopub.status.busy": "2022-05-07T14:12:30.623341Z",
     "iopub.status.idle": "2022-05-07T14:12:30.697997Z",
     "shell.execute_reply": "2022-05-07T14:12:30.696923Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.623635Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(country_df, x=\"country\", y=\"show_id\",\n",
    "             color='type', barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the top 10 content makers for Netflix and that the United States produces the most content on Netflix \n",
    "For TV shows this is followed secondly by India, then the UK\n",
    "In 10th place for movies we have Egypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.699958Z",
     "iopub.status.busy": "2022-05-07T14:12:30.699547Z",
     "iopub.status.idle": "2022-05-07T14:12:30.708712Z",
     "shell.execute_reply": "2022-05-07T14:12:30.707824Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.699902Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.710765Z",
     "iopub.status.busy": "2022-05-07T14:12:30.710249Z",
     "iopub.status.idle": "2022-05-07T14:12:30.723314Z",
     "shell.execute_reply": "2022-05-07T14:12:30.722237Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.710720Z"
    }
   },
   "outputs": [],
   "source": [
    "df['year_added'] = str(df['date_added'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.725569Z",
     "iopub.status.busy": "2022-05-07T14:12:30.724826Z",
     "iopub.status.idle": "2022-05-07T14:12:30.741591Z",
     "shell.execute_reply": "2022-05-07T14:12:30.740761Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.725529Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.743696Z",
     "iopub.status.busy": "2022-05-07T14:12:30.742922Z",
     "iopub.status.idle": "2022-05-07T14:12:30.958145Z",
     "shell.execute_reply": "2022-05-07T14:12:30.957321Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.743656Z"
    }
   },
   "outputs": [],
   "source": [
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.961629Z",
     "iopub.status.busy": "2022-05-07T14:12:30.961315Z",
     "iopub.status.idle": "2022-05-07T14:12:30.970950Z",
     "shell.execute_reply": "2022-05-07T14:12:30.969897Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.961593Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.972688Z",
     "iopub.status.busy": "2022-05-07T14:12:30.972399Z",
     "iopub.status.idle": "2022-05-07T14:12:30.981014Z",
     "shell.execute_reply": "2022-05-07T14:12:30.980260Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.972655Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.982849Z",
     "iopub.status.busy": "2022-05-07T14:12:30.982058Z",
     "iopub.status.idle": "2022-05-07T14:12:30.996038Z",
     "shell.execute_reply": "2022-05-07T14:12:30.995234Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.982807Z"
    }
   },
   "outputs": [],
   "source": [
    "df['time'] = pd.DatetimeIndex(df['date_added']).year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:30.997813Z",
     "iopub.status.busy": "2022-05-07T14:12:30.997093Z",
     "iopub.status.idle": "2022-05-07T14:12:31.008694Z",
     "shell.execute_reply": "2022-05-07T14:12:31.007817Z",
     "shell.execute_reply.started": "2022-05-07T14:12:30.997773Z"
    }
   },
   "outputs": [],
   "source": [
    "df['time'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:31.010180Z",
     "iopub.status.busy": "2022-05-07T14:12:31.009937Z",
     "iopub.status.idle": "2022-05-07T14:12:31.020822Z",
     "shell.execute_reply": "2022-05-07T14:12:31.019937Z",
     "shell.execute_reply.started": "2022-05-07T14:12:31.010149Z"
    }
   },
   "outputs": [],
   "source": [
    "df['long'] = df['time']-df['release_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:31.022659Z",
     "iopub.status.busy": "2022-05-07T14:12:31.021977Z",
     "iopub.status.idle": "2022-05-07T14:12:31.036510Z",
     "shell.execute_reply": "2022-05-07T14:12:31.035785Z",
     "shell.execute_reply.started": "2022-05-07T14:12:31.022625Z"
    }
   },
   "outputs": [],
   "source": [
    "df['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:31.038996Z",
     "iopub.status.busy": "2022-05-07T14:12:31.038304Z",
     "iopub.status.idle": "2022-05-07T14:12:31.055376Z",
     "shell.execute_reply": "2022-05-07T14:12:31.054374Z",
     "shell.execute_reply.started": "2022-05-07T14:12:31.038958Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1698987a6d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.drop(df[df.long < 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:31.056957Z",
     "iopub.status.busy": "2022-05-07T14:12:31.056717Z",
     "iopub.status.idle": "2022-05-07T14:12:31.069232Z",
     "shell.execute_reply": "2022-05-07T14:12:31.068534Z",
     "shell.execute_reply.started": "2022-05-07T14:12:31.056929Z"
    }
   },
   "outputs": [],
   "source": [
    "df['long'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-07T14:12:31.072369Z",
     "iopub.status.busy": "2022-05-07T14:12:31.071542Z",
     "iopub.status.idle": "2022-05-07T14:12:31.146815Z",
     "shell.execute_reply": "2022-05-07T14:12:31.145989Z",
     "shell.execute_reply.started": "2022-05-07T14:12:31.072316Z"
    }
   },
   "outputs": [],
   "source": [
    "time_to_screen = df.groupby(['long'])['show_id'].count().reset_index()\n",
    "\n",
    "fig = px.bar(time_to_screen, x='long', y = 'show_id')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the majority of Netflix shows and movies are relased and are on Netflix within one year, this is likely due to the productions released by Netflix Studios \n",
    "\n",
    "Ensuring a regurlar catalogue of new shows entices the viewers to keep coming back to Netflix and keeps retention "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
